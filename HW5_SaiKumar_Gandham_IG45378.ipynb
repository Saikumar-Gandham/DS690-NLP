{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b836f6e",
   "metadata": {},
   "source": [
    "#### Name : Sai Kumar Gandham\n",
    "#### Student ID : IG45378"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f313503b",
   "metadata": {},
   "source": [
    "#### 11. Learn about the affix tagger (type ** help(nltk.AffixTagger) **). Train an affix tagger and run it on some new text. Experiment with different settings for the affix length and the minimum word length. Discuss your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5f95ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class AffixTagger in module nltk.tag.sequential:\n",
      "\n",
      "class AffixTagger(ContextTagger)\n",
      " |  AffixTagger(train=None, model=None, affix_length=-3, min_stem_length=2, backoff=None, cutoff=0, verbose=False)\n",
      " |  \n",
      " |  A tagger that chooses a token's tag based on a leading or trailing\n",
      " |  substring of its word string.  (It is important to note that these\n",
      " |  substrings are not necessarily \"true\" morphological affixes).  In\n",
      " |  particular, a fixed-length substring of the word is looked up in a\n",
      " |  table, and the corresponding tag is returned.  Affix taggers are\n",
      " |  typically constructed by training them on a tagged corpus.\n",
      " |  \n",
      " |  Construct a new affix tagger.\n",
      " |  \n",
      " |  :param affix_length: The length of the affixes that should be\n",
      " |      considered during training and tagging.  Use negative\n",
      " |      numbers for suffixes.\n",
      " |  :param min_stem_length: Any words whose length is less than\n",
      " |      min_stem_length+abs(affix_length) will be assigned a\n",
      " |      tag of None by this tagger.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      AffixTagger\n",
      " |      ContextTagger\n",
      " |      SequentialBackoffTagger\n",
      " |      nltk.tag.api.TaggerI\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, train=None, model=None, affix_length=-3, min_stem_length=2, backoff=None, cutoff=0, verbose=False)\n",
      " |      :param context_to_tag: A dictionary mapping contexts to tags.\n",
      " |      :param backoff: The backoff tagger that should be used for this tagger.\n",
      " |  \n",
      " |  context(self, tokens, index, history)\n",
      " |      :return: the context that should be used to look up the tag\n",
      " |          for the specified token; or None if the specified token\n",
      " |          should not be handled by this tagger.\n",
      " |      :rtype: (hashable)\n",
      " |  \n",
      " |  encode_json_obj(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  decode_json_obj(obj) from abc.ABCMeta\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  json_tag = 'nltk.tag.sequential.AffixTagger'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ContextTagger:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  choose_tag(self, tokens, index, history)\n",
      " |      Decide which tag should be used for the specified token, and\n",
      " |      return that tag.  If this tagger is unable to determine a tag\n",
      " |      for the specified token, return None -- do not consult\n",
      " |      the backoff tagger.  This method should be overridden by\n",
      " |      subclasses of SequentialBackoffTagger.\n",
      " |      \n",
      " |      :rtype: str\n",
      " |      :type tokens: list\n",
      " |      :param tokens: The list of words that are being tagged.\n",
      " |      :type index: int\n",
      " |      :param index: The index of the word whose tag should be\n",
      " |          returned.\n",
      " |      :type history: list(str)\n",
      " |      :param history: A list of the tags for all words before *index*.\n",
      " |  \n",
      " |  size(self)\n",
      " |      :return: The number of entries in the table used by this\n",
      " |          tagger to map from contexts to tags.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from SequentialBackoffTagger:\n",
      " |  \n",
      " |  tag(self, tokens)\n",
      " |      Determine the most appropriate tag sequence for the given\n",
      " |      token sequence, and return a corresponding list of tagged\n",
      " |      tokens.  A tagged token is encoded as a tuple ``(token, tag)``.\n",
      " |      \n",
      " |      :rtype: list(tuple(str, str))\n",
      " |  \n",
      " |  tag_one(self, tokens, index, history)\n",
      " |      Determine an appropriate tag for the specified token, and\n",
      " |      return that tag.  If this tagger is unable to determine a tag\n",
      " |      for the specified token, then its backoff tagger is consulted.\n",
      " |      \n",
      " |      :rtype: str\n",
      " |      :type tokens: list\n",
      " |      :param tokens: The list of words that are being tagged.\n",
      " |      :type index: int\n",
      " |      :param index: The index of the word whose tag should be\n",
      " |          returned.\n",
      " |      :type history: list(str)\n",
      " |      :param history: A list of the tags for all words before *index*.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from SequentialBackoffTagger:\n",
      " |  \n",
      " |  backoff\n",
      " |      The backoff tagger for this tagger.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from nltk.tag.api.TaggerI:\n",
      " |  \n",
      " |  accuracy(self, gold)\n",
      " |      Score the accuracy of the tagger against the gold standard.\n",
      " |      Strip the tags from the gold standard text, retag it using\n",
      " |      the tagger, then compute the accuracy score.\n",
      " |      \n",
      " |      :param gold: The list of tagged sentences to score the tagger on.\n",
      " |      :type gold: list(list(tuple(str, str)))\n",
      " |      :rtype: float\n",
      " |  \n",
      " |  confusion(self, gold)\n",
      " |      Return a ConfusionMatrix with the tags from ``gold`` as the reference\n",
      " |      values, with the predictions from ``tag_sents`` as the predicted values.\n",
      " |      \n",
      " |      >>> from nltk.tag import PerceptronTagger\n",
      " |      >>> from nltk.corpus import treebank\n",
      " |      >>> tagger = PerceptronTagger()\n",
      " |      >>> gold_data = treebank.tagged_sents()[:10]\n",
      " |      >>> print(tagger.confusion(gold_data))\n",
      " |             |        -                                                                                     |\n",
      " |             |        N                                                                                     |\n",
      " |             |        O                                               P                                     |\n",
      " |             |        N                       J  J        N  N  P  P  R     R           V  V  V  V  V  W    |\n",
      " |             |  '     E     C  C  D  E  I  J  J  J  M  N  N  N  O  R  P  R  B  R  T  V  B  B  B  B  B  D  ` |\n",
      " |             |  '  ,  -  .  C  D  T  X  N  J  R  S  D  N  P  S  S  P  $  B  R  P  O  B  D  G  N  P  Z  T  ` |\n",
      " |      -------+----------------------------------------------------------------------------------------------+\n",
      " |          '' | <1> .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . |\n",
      " |           , |  .<15> .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . |\n",
      " |      -NONE- |  .  . <.> .  .  2  .  .  .  2  .  .  .  5  1  .  .  .  .  2  .  .  .  .  .  .  .  .  .  .  . |\n",
      " |           . |  .  .  .<10> .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . |\n",
      " |          CC |  .  .  .  . <1> .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . |\n",
      " |          CD |  .  .  .  .  . <5> .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . |\n",
      " |          DT |  .  .  .  .  .  .<20> .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . |\n",
      " |          EX |  .  .  .  .  .  .  . <1> .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . |\n",
      " |          IN |  .  .  .  .  .  .  .  .<22> .  .  .  .  .  .  .  .  .  .  3  .  .  .  .  .  .  .  .  .  .  . |\n",
      " |          JJ |  .  .  .  .  .  .  .  .  .<16> .  .  .  .  1  .  .  .  .  1  .  .  .  .  .  .  .  .  .  .  . |\n",
      " |         JJR |  .  .  .  .  .  .  .  .  .  . <.> .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . |\n",
      " |         JJS |  .  .  .  .  .  .  .  .  .  .  . <1> .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . |\n",
      " |          MD |  .  .  .  .  .  .  .  .  .  .  .  . <1> .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . |\n",
      " |          NN |  .  .  .  .  .  .  .  .  .  .  .  .  .<28> 1  1  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . |\n",
      " |         NNP |  .  .  .  .  .  .  .  .  .  .  .  .  .  .<25> .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . |\n",
      " |         NNS |  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .<19> .  .  .  .  .  .  .  .  .  .  .  .  .  .  . |\n",
      " |         POS |  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . <1> .  .  .  .  .  .  .  .  .  .  .  .  .  . |\n",
      " |         PRP |  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . <4> .  .  .  .  .  .  .  .  .  .  .  .  . |\n",
      " |        PRP$ |  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . <2> .  .  .  .  .  .  .  .  .  .  .  . |\n",
      " |          RB |  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . <4> .  .  .  .  .  .  .  .  .  .  . |\n",
      " |         RBR |  .  .  .  .  .  .  .  .  .  .  1  .  .  .  .  .  .  .  .  . <1> .  .  .  .  .  .  .  .  .  . |\n",
      " |          RP |  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . <1> .  .  .  .  .  .  .  .  . |\n",
      " |          TO |  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . <5> .  .  .  .  .  .  .  . |\n",
      " |          VB |  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . <3> .  .  .  .  .  .  . |\n",
      " |         VBD |  .  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  .  .  .  .  .  .  . <6> .  .  .  .  .  . |\n",
      " |         VBG |  .  .  .  .  .  .  .  .  .  .  .  .  .  1  .  .  .  .  .  .  .  .  .  .  . <4> .  .  .  .  . |\n",
      " |         VBN |  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  1  . <4> .  .  .  . |\n",
      " |         VBP |  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . <3> .  .  . |\n",
      " |         VBZ |  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . <7> .  . |\n",
      " |         WDT |  .  .  .  .  .  .  .  .  2  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . <.> . |\n",
      " |          `` |  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . <1>|\n",
      " |      -------+----------------------------------------------------------------------------------------------+\n",
      " |      (row = reference; col = test)\n",
      " |      <BLANKLINE>\n",
      " |      \n",
      " |      :param gold: The list of tagged sentences to run the tagger with,\n",
      " |          also used as the reference values in the generated confusion matrix.\n",
      " |      :type gold: list(list(tuple(str, str)))\n",
      " |      :rtype: ConfusionMatrix\n",
      " |  \n",
      " |  evaluate(*args, **kwargs)\n",
      " |      @deprecated: Use accuracy(gold) instead.\n",
      " |  \n",
      " |  evaluate_per_tag(self, gold, alpha=0.5, truncate=None, sort_by_count=False)\n",
      " |      Tabulate the **recall**, **precision** and **f-measure**\n",
      " |      for each tag from ``gold`` or from running ``tag`` on the tokenized\n",
      " |      sentences from ``gold``.\n",
      " |      \n",
      " |      >>> from nltk.tag import PerceptronTagger\n",
      " |      >>> from nltk.corpus import treebank\n",
      " |      >>> tagger = PerceptronTagger()\n",
      " |      >>> gold_data = treebank.tagged_sents()[:10]\n",
      " |      >>> print(tagger.evaluate_per_tag(gold_data))\n",
      " |         Tag | Prec.  | Recall | F-measure\n",
      " |      -------+--------+--------+-----------\n",
      " |          '' | 1.0000 | 1.0000 | 1.0000\n",
      " |           , | 1.0000 | 1.0000 | 1.0000\n",
      " |      -NONE- | 0.0000 | 0.0000 | 0.0000\n",
      " |           . | 1.0000 | 1.0000 | 1.0000\n",
      " |          CC | 1.0000 | 1.0000 | 1.0000\n",
      " |          CD | 0.7143 | 1.0000 | 0.8333\n",
      " |          DT | 1.0000 | 1.0000 | 1.0000\n",
      " |          EX | 1.0000 | 1.0000 | 1.0000\n",
      " |          IN | 0.9167 | 0.8800 | 0.8980\n",
      " |          JJ | 0.8889 | 0.8889 | 0.8889\n",
      " |         JJR | 0.0000 | 0.0000 | 0.0000\n",
      " |         JJS | 1.0000 | 1.0000 | 1.0000\n",
      " |          MD | 1.0000 | 1.0000 | 1.0000\n",
      " |          NN | 0.8000 | 0.9333 | 0.8615\n",
      " |         NNP | 0.8929 | 1.0000 | 0.9434\n",
      " |         NNS | 0.9500 | 1.0000 | 0.9744\n",
      " |         POS | 1.0000 | 1.0000 | 1.0000\n",
      " |         PRP | 1.0000 | 1.0000 | 1.0000\n",
      " |        PRP$ | 1.0000 | 1.0000 | 1.0000\n",
      " |          RB | 0.4000 | 1.0000 | 0.5714\n",
      " |         RBR | 1.0000 | 0.5000 | 0.6667\n",
      " |          RP | 1.0000 | 1.0000 | 1.0000\n",
      " |          TO | 1.0000 | 1.0000 | 1.0000\n",
      " |          VB | 1.0000 | 1.0000 | 1.0000\n",
      " |         VBD | 0.8571 | 0.8571 | 0.8571\n",
      " |         VBG | 1.0000 | 0.8000 | 0.8889\n",
      " |         VBN | 1.0000 | 0.8000 | 0.8889\n",
      " |         VBP | 1.0000 | 1.0000 | 1.0000\n",
      " |         VBZ | 1.0000 | 1.0000 | 1.0000\n",
      " |         WDT | 0.0000 | 0.0000 | 0.0000\n",
      " |          `` | 1.0000 | 1.0000 | 1.0000\n",
      " |      <BLANKLINE>\n",
      " |      \n",
      " |      :param gold: The list of tagged sentences to score the tagger on.\n",
      " |      :type gold: list(list(tuple(str, str)))\n",
      " |      :param alpha: Ratio of the cost of false negative compared to false\n",
      " |          positives, as used in the f-measure computation. Defaults to 0.5,\n",
      " |          where the costs are equal.\n",
      " |      :type alpha: float\n",
      " |      :param truncate: If specified, then only show the specified\n",
      " |          number of values.  Any sorting (e.g., sort_by_count)\n",
      " |          will be performed before truncation. Defaults to None\n",
      " |      :type truncate: int, optional\n",
      " |      :param sort_by_count: Whether to sort the outputs on number of\n",
      " |          occurrences of that tag in the ``gold`` data, defaults to False\n",
      " |      :type sort_by_count: bool, optional\n",
      " |      :return: A tabulated recall, precision and f-measure string\n",
      " |      :rtype: str\n",
      " |  \n",
      " |  f_measure(self, gold, alpha=0.5)\n",
      " |      Compute the f-measure for each tag from ``gold`` or from running ``tag``\n",
      " |      on the tokenized sentences from ``gold``. Then, return the dictionary\n",
      " |      with mappings from tag to f-measure. The f-measure is the harmonic mean\n",
      " |      of the ``precision`` and ``recall``, weighted by ``alpha``.\n",
      " |      In particular, given the precision *p* and recall *r* defined by:\n",
      " |      \n",
      " |      - *p* = true positive / (true positive + false negative)\n",
      " |      - *r* = true positive / (true positive + false positive)\n",
      " |      \n",
      " |      The f-measure is:\n",
      " |      \n",
      " |      - *1/(alpha/p + (1-alpha)/r)*\n",
      " |      \n",
      " |      With ``alpha = 0.5``, this reduces to:\n",
      " |      \n",
      " |      - *2pr / (p + r)*\n",
      " |      \n",
      " |      :param gold: The list of tagged sentences to score the tagger on.\n",
      " |      :type gold: list(list(tuple(str, str)))\n",
      " |      :param alpha: Ratio of the cost of false negative compared to false\n",
      " |          positives. Defaults to 0.5, where the costs are equal.\n",
      " |      :type alpha: float\n",
      " |      :return: A mapping from tags to precision\n",
      " |      :rtype: Dict[str, float]\n",
      " |  \n",
      " |  precision(self, gold)\n",
      " |      Compute the precision for each tag from ``gold`` or from running ``tag``\n",
      " |      on the tokenized sentences from ``gold``. Then, return the dictionary\n",
      " |      with mappings from tag to precision. The precision is defined as:\n",
      " |      \n",
      " |      - *p* = true positive / (true positive + false negative)\n",
      " |      \n",
      " |      :param gold: The list of tagged sentences to score the tagger on.\n",
      " |      :type gold: list(list(tuple(str, str)))\n",
      " |      :return: A mapping from tags to precision\n",
      " |      :rtype: Dict[str, float]\n",
      " |  \n",
      " |  recall(self, gold) -> Dict[str, float]\n",
      " |      Compute the recall for each tag from ``gold`` or from running ``tag``\n",
      " |      on the tokenized sentences from ``gold``. Then, return the dictionary\n",
      " |      with mappings from tag to recall. The recall is defined as:\n",
      " |      \n",
      " |      - *r* = true positive / (true positive + false positive)\n",
      " |      \n",
      " |      :param gold: The list of tagged sentences to score the tagger on.\n",
      " |      :type gold: list(list(tuple(str, str)))\n",
      " |      :return: A mapping from tags to recall\n",
      " |      :rtype: Dict[str, float]\n",
      " |  \n",
      " |  tag_sents(self, sentences)\n",
      " |      Apply ``self.tag()`` to each element of *sentences*.  I.e.::\n",
      " |      \n",
      " |          return [self.tag(sent) for sent in sentences]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from nltk.tag.api.TaggerI:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tag import AffixTagger\n",
    "from nltk.corpus import brown\n",
    "\n",
    "help(nltk.AffixTagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c9581cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('She', None), ('sells', 'NNS'), ('seashells', 'NNS'), ('by', None), ('the', None), ('seashore', 'IN'), ('.', None)]\n"
     ]
    }
   ],
   "source": [
    "# Here we are training the AffixTagger\n",
    "train_sents = brown.tagged_sents(categories='news')[:500]  # Using a portion of the Brown corpus for training\n",
    "affix_tagger = AffixTagger(train_sents, affix_length=-3, min_stem_length=2)\n",
    "\n",
    "# Example of running the tagger on a different text\n",
    "test_text = \"She sells seashells by the seashore.\"\n",
    "tagged_text = affix_tagger.tag(nltk.word_tokenize(test_text))\n",
    "print(tagged_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41bea17",
   "metadata": {},
   "source": [
    "- \"She\" doesn't have a tag because it's not clear what part of speech it is.\n",
    "- \"sells\" and \"seashells\" are both identified as plural nouns (NNS).\n",
    "- \"by\" and \"the\" don't have tags, meaning the tagger couldn't determine their part of speech.\n",
    "- \"seashore\" is mistakenly tagged as a preposition or subordinating conjunction (IN), which is incorrect.\n",
    "- \".\" doesn't have a tag because it's punctuation.\n",
    "\n",
    "Overall, the AffixTagger correctly identified \"sells\" and \"seashells\" as plural nouns but struggled with other words, assigning incorrect tags to some of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08d08c0",
   "metadata": {},
   "source": [
    "#### 14. Use ** sorted() ** and ** set() ** to get a sorted list of tags used in the Brown corpus, removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c97ff68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'\", \"''\", '(', '(-HL', ')', ')-HL', '*', '*-HL', '*-NC', '*-TL', ',', ',-HL', ',-NC', ',-TL', '--', '---HL', '.', '.-HL', '.-NC', '.-TL', ':', ':-HL', ':-TL', 'ABL', 'ABN', 'ABN-HL', 'ABN-NC', 'ABN-TL', 'ABX', 'AP', 'AP$', 'AP+AP-NC', 'AP-HL', 'AP-NC', 'AP-TL', 'AT', 'AT-HL', 'AT-NC', 'AT-TL', 'AT-TL-HL', 'BE', 'BE-HL', 'BE-TL', 'BED', 'BED*', 'BED-NC', 'BEDZ', 'BEDZ*', 'BEDZ-HL', 'BEDZ-NC', 'BEG', 'BEM', 'BEM*', 'BEM-NC', 'BEN', 'BEN-TL', 'BER', 'BER*', 'BER*-NC', 'BER-HL', 'BER-NC', 'BER-TL', 'BEZ', 'BEZ*', 'BEZ-HL', 'BEZ-NC', 'BEZ-TL', 'CC', 'CC-HL', 'CC-NC', 'CC-TL', 'CC-TL-HL', 'CD', 'CD$', 'CD-HL', 'CD-NC', 'CD-TL', 'CD-TL-HL', 'CS', 'CS-HL', 'CS-NC', 'CS-TL', 'DO', 'DO*', 'DO*-HL', 'DO+PPSS', 'DO-HL', 'DO-NC', 'DO-TL', 'DOD', 'DOD*', 'DOD*-TL', 'DOD-NC', 'DOZ', 'DOZ*', 'DOZ*-TL', 'DOZ-HL', 'DOZ-TL', 'DT', 'DT$', 'DT+BEZ', 'DT+BEZ-NC', 'DT+MD', 'DT-HL', 'DT-NC', 'DT-TL', 'DTI', 'DTI-HL', 'DTI-TL', 'DTS', 'DTS+BEZ', 'DTS-HL', 'DTX', 'EX', 'EX+BEZ', 'EX+HVD', 'EX+HVZ', 'EX+MD', 'EX-HL', 'EX-NC', 'FW-*', 'FW-*-TL', 'FW-AT', 'FW-AT+NN-TL', 'FW-AT+NP-TL', 'FW-AT-HL', 'FW-AT-TL', 'FW-BE', 'FW-BER', 'FW-BEZ', 'FW-CC', 'FW-CC-TL', 'FW-CD', 'FW-CD-TL', 'FW-CS', 'FW-DT', 'FW-DT+BEZ', 'FW-DTS', 'FW-HV', 'FW-IN', 'FW-IN+AT', 'FW-IN+AT-T', 'FW-IN+AT-TL', 'FW-IN+NN', 'FW-IN+NN-TL', 'FW-IN+NP-TL', 'FW-IN-TL', 'FW-JJ', 'FW-JJ-NC', 'FW-JJ-TL', 'FW-JJR', 'FW-JJT', 'FW-NN', 'FW-NN$', 'FW-NN$-TL', 'FW-NN-NC', 'FW-NN-TL', 'FW-NN-TL-NC', 'FW-NNS', 'FW-NNS-NC', 'FW-NNS-TL', 'FW-NP', 'FW-NP-TL', 'FW-NPS', 'FW-NPS-TL', 'FW-NR', 'FW-NR-TL', 'FW-OD-NC', 'FW-OD-TL', 'FW-PN', 'FW-PP$', 'FW-PP$-NC', 'FW-PP$-TL', 'FW-PPL', 'FW-PPL+VBZ', 'FW-PPO', 'FW-PPO+IN', 'FW-PPS', 'FW-PPSS', 'FW-PPSS+HV', 'FW-QL', 'FW-RB', 'FW-RB+CC', 'FW-RB-TL', 'FW-TO+VB', 'FW-UH', 'FW-UH-NC', 'FW-UH-TL', 'FW-VB', 'FW-VB-NC', 'FW-VB-TL', 'FW-VBD', 'FW-VBD-TL', 'FW-VBG', 'FW-VBG-TL', 'FW-VBN', 'FW-VBZ', 'FW-WDT', 'FW-WPO', 'FW-WPS', 'HV', 'HV*', 'HV+TO', 'HV-HL', 'HV-NC', 'HV-TL', 'HVD', 'HVD*', 'HVD-HL', 'HVG', 'HVG-HL', 'HVN', 'HVZ', 'HVZ*', 'HVZ-NC', 'HVZ-TL', 'IN', 'IN+IN', 'IN+PPO', 'IN-HL', 'IN-NC', 'IN-TL', 'IN-TL-HL', 'JJ', 'JJ$-TL', 'JJ+JJ-NC', 'JJ-HL', 'JJ-NC', 'JJ-TL', 'JJ-TL-HL', 'JJ-TL-NC', 'JJR', 'JJR+CS', 'JJR-HL', 'JJR-NC', 'JJR-TL', 'JJS', 'JJS-HL', 'JJS-TL', 'JJT', 'JJT-HL', 'JJT-NC', 'JJT-TL', 'MD', 'MD*', 'MD*-HL', 'MD+HV', 'MD+PPSS', 'MD+TO', 'MD-HL', 'MD-NC', 'MD-TL', 'NIL', 'NN', 'NN$', 'NN$-HL', 'NN$-TL', 'NN+BEZ', 'NN+BEZ-TL', 'NN+HVD-TL', 'NN+HVZ', 'NN+HVZ-TL', 'NN+IN', 'NN+MD', 'NN+NN-NC', 'NN-HL', 'NN-NC', 'NN-TL', 'NN-TL-HL', 'NN-TL-NC', 'NNS', 'NNS$', 'NNS$-HL', 'NNS$-NC', 'NNS$-TL', 'NNS$-TL-HL', 'NNS+MD', 'NNS-HL', 'NNS-NC', 'NNS-TL', 'NNS-TL-HL', 'NNS-TL-NC', 'NP', 'NP$', 'NP$-HL', 'NP$-TL', 'NP+BEZ', 'NP+BEZ-NC', 'NP+HVZ', 'NP+HVZ-NC', 'NP+MD', 'NP-HL', 'NP-NC', 'NP-TL', 'NP-TL-HL', 'NPS', 'NPS$', 'NPS$-HL', 'NPS$-TL', 'NPS-HL', 'NPS-NC', 'NPS-TL', 'NR', 'NR$', 'NR$-TL', 'NR+MD', 'NR-HL', 'NR-NC', 'NR-TL', 'NR-TL-HL', 'NRS', 'NRS-TL', 'OD', 'OD-HL', 'OD-NC', 'OD-TL', 'PN', 'PN$', 'PN+BEZ', 'PN+HVD', 'PN+HVZ', 'PN+MD', 'PN-HL', 'PN-NC', 'PN-TL', 'PP$', 'PP$$', 'PP$-HL', 'PP$-NC', 'PP$-TL', 'PPL', 'PPL-HL', 'PPL-NC', 'PPL-TL', 'PPLS', 'PPO', 'PPO-HL', 'PPO-NC', 'PPO-TL', 'PPS', 'PPS+BEZ', 'PPS+BEZ-HL', 'PPS+BEZ-NC', 'PPS+HVD', 'PPS+HVZ', 'PPS+MD', 'PPS-HL', 'PPS-NC', 'PPS-TL', 'PPSS', 'PPSS+BEM', 'PPSS+BER', 'PPSS+BER-N', 'PPSS+BER-NC', 'PPSS+BER-TL', 'PPSS+BEZ', 'PPSS+BEZ*', 'PPSS+HV', 'PPSS+HV-TL', 'PPSS+HVD', 'PPSS+MD', 'PPSS+MD-NC', 'PPSS+VB', 'PPSS-HL', 'PPSS-NC', 'PPSS-TL', 'QL', 'QL-HL', 'QL-NC', 'QL-TL', 'QLP', 'RB', 'RB$', 'RB+BEZ', 'RB+BEZ-HL', 'RB+BEZ-NC', 'RB+CS', 'RB-HL', 'RB-NC', 'RB-TL', 'RBR', 'RBR+CS', 'RBR-NC', 'RBT', 'RN', 'RP', 'RP+IN', 'RP-HL', 'RP-NC', 'RP-TL', 'TO', 'TO+VB', 'TO-HL', 'TO-NC', 'TO-TL', 'UH', 'UH-HL', 'UH-NC', 'UH-TL', 'VB', 'VB+AT', 'VB+IN', 'VB+JJ-NC', 'VB+PPO', 'VB+RP', 'VB+TO', 'VB+VB-NC', 'VB-HL', 'VB-NC', 'VB-TL', 'VBD', 'VBD-HL', 'VBD-NC', 'VBD-TL', 'VBG', 'VBG+TO', 'VBG-HL', 'VBG-NC', 'VBG-TL', 'VBN', 'VBN+TO', 'VBN-HL', 'VBN-NC', 'VBN-TL', 'VBN-TL-HL', 'VBN-TL-NC', 'VBZ', 'VBZ-HL', 'VBZ-NC', 'VBZ-TL', 'WDT', 'WDT+BER', 'WDT+BER+PP', 'WDT+BEZ', 'WDT+BEZ-HL', 'WDT+BEZ-NC', 'WDT+BEZ-TL', 'WDT+DO+PPS', 'WDT+DOD', 'WDT+HVZ', 'WDT-HL', 'WDT-NC', 'WP$', 'WPO', 'WPO-NC', 'WPO-TL', 'WPS', 'WPS+BEZ', 'WPS+BEZ-NC', 'WPS+BEZ-TL', 'WPS+HVD', 'WPS+HVZ', 'WPS+MD', 'WPS-HL', 'WPS-NC', 'WPS-TL', 'WQL', 'WQL-TL', 'WRB', 'WRB+BER', 'WRB+BEZ', 'WRB+BEZ-TL', 'WRB+DO', 'WRB+DOD', 'WRB+DOD*', 'WRB+DOZ', 'WRB+IN', 'WRB+MD', 'WRB-HL', 'WRB-NC', 'WRB-TL', '``']\n"
     ]
    }
   ],
   "source": [
    "# Get all tagged words from the Brown Corpus\n",
    "tagged_words = brown.tagged_words()\n",
    "\n",
    "# Extract tags and convert them to a set to remove duplicates\n",
    "tags_set = set(tag for word, tag in tagged_words)\n",
    "\n",
    "# Sort the set of tags\n",
    "sorted_tags = sorted(tags_set)\n",
    "\n",
    "print(sorted_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43521057",
   "metadata": {},
   "source": [
    "#### 15. Write programs to process the Brown Corpus and find answers to the following questions:\n",
    "a. Which nouns are more common in their plural form, rather than their singular form? (Only consider regular plurals, formed with the ** -s ** suffix.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf6b735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f395a455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouns more common in plural form: {'Camera', 'Investor', 'cartoon', 'turnpike', 'metaphysical', 'defender', 'duct', 'ailment', 'nude', 'working', 'scholar', 'Idea', 'psychiatrist', 'Teacher', 'alcoholic', 'publisher', 'intermediate', 'omission', '1950', 'carrier', 'banker', 'urging', 'riddle', 'Demon', 'hit', 'referral', 'obligation', 'batten', 'polymer', 'Superintendent', 'Lot', 'singer', 'finding', 'symptom', 'geologist', 'parasite', 'movie', '45-degree', 'consonant', 'lip', 'Loan', 'conservative', 'compulsive', 'runner', 'up', 'four', 'lark', 'ballistic', 'tranquilizer', 'cardinal', 'swell', 'Corporation', 'headline', 'fee', 'guest', 'Girl', 'lashing', 'aberration', 'intangible', 'neighbor', 'sensitive', 'dropping', 'grouping', 'rule', 'nuance', 'believer', 'plastic', 'no', 'bronchiole', 'Song', 'regulation', 'norm', 'aborigine', 'adviser', 'modification', 'implication', 'lobule', 'cop', 'painting', 'franc', '2-year-old', 'sneaker', 'official', 'bound', 'cleaner', 'fathom', 'Farmer', 'shim', 'emerald', 'ingredient', 'generalization', 'scientist', 'surrounding', 're-run', 'proponent', 'transformer', 'doll', 'bun', 'rim-fire', 'scandal', 'Command', 'Advance', 'Writer', 'card', 'endearment', 'duck', 'hydride', 'third', 'Dog', 'Other', 'practitioner', 'scholastic', 'duffer', 'investor', 'alloy', 'lilac', 'Measure', 'mystic', 'superior', 'towel', 'peacock', 'Person', 'document', 'wrestling', 'pamphlet', 'skate', 'vitamin', 'loyalist', 'flare', 'speculator', 'grad', 'odd', 'siren', 'customer', 'interrelationship', 'Dealer', 'pink', 'allusion', 'Step', 'restriction', 'dynamic', 'Proprietorship', 'reagent', 'antecedent', 'musician', 'two', 'vase', 'adapter', 'highlight', 'revenue', 'cookie', 'factor', 'eclipse', 'Export', 'titter', 'Traveler', 'Survey', 'Nation', 'ligand', 'brake', 'Orange', 'limit', 'Culture', 'denomination', 'evocation', 'Session', 'doing', 'spectator', 'theatrical', 'teenager', 'spewing', 'Dean', 'scripture', 'cooperative', 'kissing', 'noun', 'Criminal', 'bite', 'drier', 'stain', 'drug', 'eyelid', 'Gain', 'Indication', 'stair', 'Member', 'polyphosphate', 'slack', 'map', 'Regular', 'trait', 'shaker', 'vine', 'bevel', 'stamp', 'follower', 'colored', 'Chart', 'Fund', 'supervisor', 'shunt', 'relative', 'chunk', 'tribe', 'modern', 'spice', 'sacrament', 'condition', 'billion', 'atom', 'carving', 'entertainer', 'inmate', 'instrumental', 'Highway', 'critic', 'weapon', 'perturbation', 'Team', 'word', 'complication', 'forecast', 'trader', 'improvisation', 'treasure', 'manual', 'controller', 'ant', 'concessionaire', 'thank', 'dystopia', 'bond', 'Judge', 'watershed', 'stocking', 'dune', 'outboard', 'airfield', 'Avocado', 'giggle', 'synthetic', 'marina', 'voter', 'rite', 'wrap', 'Increase', 'eye', 'thug', 'plaque', 'tangent', 'interface', 'ad', 'pupil', 'competitor', 'Vineyard', 'tenth', 'Problem', 'eccentric', 'fingering', 'tank', 'leaflet', 'Play', 'silicate', 'sensor', 'postulate', 'crackpot', 'Associate', 'installation', 'sediment', 'vow', 'cheekbone', 'Intangible', 'hundred', 'fete', 'grape', 'acre', 'member', 'Reference', 'infestation', 'vault', 'nail', 'appointee', 'tick', 'pajama', 'bud', 'racketeer', 'Oil', 'Order', 'these', 'native', 'rogue', 'feature', 'soybean', 'commercial', 'candidate', 'farmer', 'claw', 'more', 'barricade', 'passenger', 'Advertiser', 'leak', 'Correction', 'gasp', 'confine', 'affair', 'camper', 'counterpart', 'thing', 'valve', 'bootlegger', 'knee', 'eyebrow', 'intellectual', 'resultant', 'memoir', 'canon', 'limb', 'yacht', 'outburst', 'trustee', 'taxpayer', 'puddle', 'parameter', 'fighter', 'tonic', 'gust', 'Connection', 'loudspeaker', 'antic', 'hub', 'progression', 'Coconut', 'Number', 'star', 'abstract', 'rein', 'bough', 'binder', 'submarine', 'dictate', 'nostril', 'Reporter', 'Banker', 'other', 'specie', 'Wire', 'Scholar', 'buyer', 'bubble', 'acoustic', 'import', 'Attorney', 'Cow', 'innocent', 'premise', 'specialist', 'stray', 'recruit', 'Score', 'bifocal', 'inboard', 'steroid', 'variable', 'undergraduate', 'cube', 'rattlesnake', 'incompatible', 'proceeding', 'Institution', 'frank', 'costume', 'Magnum', 'Hazard', 'stump', 'bee', 'bug', 'calorie', 'wave', 'institution', 'milligram', 'representative', 'poem', 'tidbit', 'footstep', 'employee', 'Poet', 'furnishing', 'vendor', 'caller', 'Station', 'conjugate', 'Start', 'grocer', 'sale', 'performer', 'Abstraction', 'centimeter', 'antiquarian', 'spacer', 'senator', 'Original', 'repulsion', 'dresser', 'picker', 'Thank', 'linguist', 'Invitation', 'gymnast', 'Crowd', 'Reading', 'Missile', 'colonial', 'lay', 'barrier', 'elephant', 'lodging', 'surfactant', 'short', 'epicycle', 'laurel', 'libertie', 'Make', 'sole', 'Bottom', 'flower', 'House', 'relation', 'feather', 'Share', 'curl', 'Ship', 'rocket', 'basic', 'Evening', 'three', 'wrinkle', 'Hurt', 'boot', 'vehicle', 'determinant', 'tactic', 'notable', 'hinge', 'receipt', 'landmark', 'contour', 'sailboat', 'creeper', 'overhang', 'admonition', 'Zero', 'nothing', 'aerial', 'remark', 'clod', 'cosmetic', 'Thousand', 'cell', 'retailer', 'Development', 'chore', 'extra', 'million', 'planet', 'investigator', 'mile', 'predisposition', 'propagandist', 'promoter', 'outsider', 'comrade', 'attribute', 'monitor', 'protease', 'Question', 'specific', '1960', 'troop', 'Record', 'inflection', 'descendant', 'white', 'deep', 'proceed', 'negotiation', 'poster', 'mug', 'expert', 'pier', 'salon', 'gutter', 'coordinate', 'vista', 'Interview', 'deliberation', 'favorite', 'Direction', 'crater', 'deltoid', 'mean', 'explosive', 'herpetologist', 'technician', 'reporter', 'coping', 'Strike', 'prolusion', 'auditor', '90-degree', 'Drum', 'lapel', 'initial', 'foreigner', 'spoke', 'abolitionist', 'shareholder', 'meteor', 'like', 'endowment', 'Measurement', 'event', 'two-week', 'pinning', 'ghoul', 'Pilot', 'insect', 'migrant', 'Case', 'barbarian', 'injunction', 'pledge', 'fund', 'strap', 'paw', 'prerogative', 'affiliation', 'Seed', 'banshee', 'Feeling', 'out', 'secant', 'visitor', 'superlative', 'tear', 'trapping', 'Change', 'nun', 'System', 'vital', 'dislocation', 'insecticide', 'normal', 'Representative', 'organism', 'Look', 'sock', 'simple', 'eatable', 'Eye', 'hitter', 'qualification', 'classic', 'constituent', 'therefore', 'enthusiast', 'preserve', 'moral', 'Leave', 'Official', 'plate', 'comedie', 'disc', 'pebble', 'tenant', 'Fraction', 'bristle', 'observation', 'volunteer', 'serpent', 'ethic', 'enzyme', 'sag', 'Want', 'Star', 'gallon', 'boasting', 'item', 'exploit', 'tektite', 'miner', 'professional', 'Conference', 'hue', 'Illustration', 'Officer', 'compound', 'pacer', 'infidel', 'advisor', 'clothe', 'imagining', 'Town', 'guerrilla', 'warrior', 'Boat', 'associate', 'suburb', 'silhouette', 'year', 'robber', 'brothel', 'invader', 'boo', 'batterie', 'cuff', 'Sign', 'headache', 'orchard', 'patron', 'Trooper', 'noble', 'diagonal', 'subordinate', 'tentacle', 'employe', 'immigrant', 'nut', 'Thing', 'groove', 'gassing', 'facet', 'Trustee', 'conqueror', 'bruise', 'tablespoon', 'win', 'stunt', 'pirate', 'homosexual', 'dividend', 'tree', 'Set', 'slave', 'maneuver', 'irregular', 'custom', 'internationalist', 'sailor', 'surmise', '1890', 'participant', 'disciple', 'catalog', 'gallant', 'creature', 'traitor', 'integral', 'gunner', 'Cocktail', 'term', 'nutrient', 'Governor', 'teen-ager', 'surrealist', 'student', 'weed', 'Market', 'liberal', 'trailer', 'dollar', 'ton', 'probe', 'measurement', 'grotesque', 'megaton', 'motorist', 'fuck', 'Liberal', 'applicant', 'Painting', 'armament', 'burglar', 'Bird', 'legislator', 'spouse', 'bribe', 'error', 'Design', 'skipper', 'down', 'critter', 'anionic', 'Example', 'parent', 'user', 'firecracker', 'conformist', 'youngster', 'bumblebee', 'heroic', 'fabric', 'Artist', 'listener', 'asset', 'Bullet', 'azalea', 'Glaze', 'commitment', 'romantic', 'tough', 'rut', 'cipher', 'urn', 'antagonist', 'nightclub', 'particle', 'mill', 'sweet', 'medal', 'hostage', 'striving', 'bird', 'snag', 'channel', 'Car', 'rupee', 'rodent', 'component', 'Model', 'Moral', 'bidder', 'ten', 'draper', 'periodical', 'Mine', 'subsystem', 'projection', 'axe', 'fan', 'contraceptive', 'robot', 'slipper', 'sonata', 'requirement', 'monosyllable', 'five', 'extractor', 'manifestation', 'Book', 'defect', 'Pagan', 'hoof', 'dealing', 'fragment', 'carrot', 'athletic', 'circumstance', 'transient', 'epithet', 'ellipsoid', 'casual', 'oyster', 'pillar', 'Graduate', 'thicket', 'sore', 'merchant', 'spike', 'suitor', 'Judgment', 'trouser', 'Snake', 'triplet', 'Result', 'solid', 'stockholder', 'Head', 'rating', 'revision', 'narcotic', 'byproduct', 'lower', 'settler', 'Apologie', 'photographer', 'specification', 'rib', \"'60\", 'grenade', 'verb', 'contributor', 'jewel', 'happening', 'Fight', 'terminal', 'Employee', 'Sponsor', 'microorganism', 'defendant', 'ether', 'shaving', 'moderate', 'song', 'vocal', 'Application', 'ear', 'mortal', 'gymnastic', 'planner', 'deviant', 'Realtor', 'chop', 'adjective', 'demon', 'knuckle', 'adherent', 'authorization', 'gangster', 'oilseed', 'villain', 'occupant', 'Trader', 'generalist', 'drawing', 'walnut', 'helmet', 'Sentiment', 'anterior', 'Film', 'politician', 'extract', 'people', 'Dream', 'lament', 'gadget', 'feud', 'earning', 'Say', 'predecessor', 'active', 'Name', 'jerking', 'additive', 'product', 'seeker', 'Reef', 'Flat', 'ion', 'molecule', 'fundamental', 'topic', 'Aid', 'pore', 'rendition', 'underwriter', 'comet', 'Solution', 'employer', 'catkin', 'offensive', 'peer', 'Relative', 'Boy', 'resident', 'Course', 'ray', 'trimming', 'hour', 'allowance', 'wavelength', 'independent', 'dealer', 'commissioner', 'imperfection', 'commune', 'teamster', 'peasant', 'fat', 'congratulation', 'psychologist', 'accomplishment', 'Junior', 'Regulation', 'consequence', 'cape', 'Plan', 'Student', 'Investigation', 'concession', 'shipment', 'concentrate', 'backyard', 'bomb', 'emotion', 'personage', 'Flock', 'arm', 'Letter', 'leading', 'survivalist', 'subversive', 'twin', 'schoolmate', 'organ', 'ill', 'leg', 'deductible', 'Job', 'escapade', 'delegate', 'indicator', 'rebel', 'sport', 'instruction', 'servant', 'Observer', 'skylight', 'redcoat', 'blossom', 'compliment', 'convert', 'interval', 'gut', 'disclosure', 'export', 'universal', 'decree', 'collaborator', 'speculation', 'newlywed', 'dimension', 'leave', 'observer', 'hopeful', 'anti-Communist', 'shrub', 'player', 'expectation', 'closeup', 'liter', 'guardian', 'weave', 'final', 'fin', 'resistor', 'soldier', 'citizen', 'vegetable', 'manufacturer', '1940', 'aye', 'burn', 'crystallite', 'supporter', 'meter', 'wing', 'appliance', 'smelt', 'silo', 'disadvantage', 'thousandth', 'reservation', 'Marina', 'scenic', 'clove', 'headquarter', 'heel', 'element', 'filbert', 'leaving', 'Return', 'cloud', '1920', 'pheasant', 'libertarian', 'expenditure', 'flip', 'finger', 'Year', 'loin', 'belonging', 'ripple', 'classmate', 'steward', 'assessor', 'sausage', 'courtier', 'dolphin', 'resource', 'tavern', 'theologian', 'realtor', 'insurgent', 'arrangement', 'thousand', 'meteorite', 'Statue', 'outbreak', 'swelling', 'honeybee', 'paragraph', 'Payment', 'Expenditure', 'dependent', 'chant', 'deduction', 'Picture', 'Sound', 'panel', 'Experiment', 'syllable', 'absolute', 'limitation', 'overture', 'bracket', 'sweeping', 'ramification', 'Report', 'winning', 'prisoner', 'spoil', 'hugging', 'Line', 'Estimate', 'cart', 'Guest', 'implement', 'greeting', 'aspect', 'friend', 'musing', 'dose', 'technique', 'drum', 'minute', 'elder', 'remain', 'dipole', 'characteristic', 'incumbent', 'lag', 'makeshift', 'month', 'lyric', 'Doctor', 'step', 'initiate', 'standard', 'incidental', 'Area', 'egg', 'advertisement', 'Circumstance', '1930', 'Test', 'colleague', 'diver', 'grower', 'cutter', 'marking', 'ideal', 'Individual', 'leader', 'shred', 'object', 'overall', 'bean', 'mountain', 'saving', 'survivor', 'aspiration', 'angel', 'national', '1970', 'toy', 'commoner', 'hike', 'live', 'Color', 'vineyard', 'Senator', 'researcher', 'nerve', 'Bid', 'topping', 'Force', 'broker', 'upland', 'motive', 'wary', 'secularist', 'incompetent', 'giant', 'shoe', 'wrestle', 'biscuit', 'booklet', 'prop', 'Train', 'gram', 'purge', 'kenning', 'supermarket', 'trump', 'prime', 'moth', 'mine', 'Diet', 'rigid', 'mechanic', 'fill-in', 'Track', 'locale', 'Plane', 'destroyer', 'Citizen', 'directive', 'appropriation', 'recrimination', 'bomber', 'wandering', 'one', 'spade', 'being', 'accommodation', 'probing', 'Flower', 'pageant', 'teen', 'experiment', 'diehard', 'bushel', 'Operation', 'revelling', 'lung', 'Method', 'jowl', 'Northerner', 'lobe', 'yard', 'savage', 'pound', 'sedan', 'chromatic', 'Cost', 'bitter', 'regular', 'Chestnut', 'spiritual', 'mammal', 'Speaker', 'maker', 'Appeal', 'toe', 'worker', 'ruler', 'adverb', 'method', 'precept'}\n"
     ]
    }
   ],
   "source": [
    "# Get tagged words from the Brown Corpus\n",
    "brown_tagged = brown.tagged_words()\n",
    "\n",
    "# let's first initialize a ConditionalFreqDist to count occurrences of singular and plural forms\n",
    "cfd = nltk.ConditionalFreqDist(brown_tagged)\n",
    "\n",
    "# let's initialize a set to store nouns that are more common in plural form\n",
    "common_plural_nouns = set()\n",
    "\n",
    "# Iterate over each word in the Brown Corpus\n",
    "for word in set(brown.words()):\n",
    "    \n",
    "    # now here we have to check if the plural form occurs more frequently than the singular form\n",
    "    if cfd[word+'s']['NNS'] > cfd[word]['NN']:\n",
    "        common_plural_nouns.add(word)\n",
    "\n",
    "print(\"Nouns more common in plural form:\", common_plural_nouns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea1c00b",
   "metadata": {},
   "source": [
    "b. Which word has the greatest number of distinct tags. What are they, and what do they represent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3132e969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word with the greatest number of distinct tags: that\n",
      "Tags for the word: {'CS-NC', 'WPS-HL', 'WPS', 'NIL', 'CS', 'DT', 'WPO', 'WPS-NC', 'WPO-NC', 'CS-HL', 'DT-NC', 'QL'}\n"
     ]
    }
   ],
   "source": [
    "word_tags = defaultdict(set)\n",
    "for word, tag in brown.tagged_words():\n",
    "    word_tags[word].add(tag)\n",
    "\n",
    "word_with_most_tags, num_tags = max(word_tags.items(), key=lambda x: len(x[1]))\n",
    "print(\"Word with the greatest number of distinct tags:\", word_with_most_tags)\n",
    "print(\"Tags for the word:\", num_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c44e1dd",
   "metadata": {},
   "source": [
    "The word with the greatest number of distinct tags in the Brown Corpus is \"that\". Here are the tags associated with it and what they represent:\n",
    "\n",
    "1. NIL: This indicates that the word \"that\" doesn't have a specific tag in certain contexts.\n",
    "2. QL: This tag is used for qualifiers or intensifiers that modify adjectives or adverbs, often indicating the degree or extent (e.g., \"very\").\n",
    "3. WPS-NC: This tag represents a possessive relative pronoun in non-contract form (e.g., \"whose\").\n",
    "4. WPO-NC: This tag represents an objective relative pronoun in non-contract form (e.g., \"whom\").\n",
    "5. CS-NC: This tag represents a subordinating conjunction in non-contract form (e.g., \"while\").\n",
    "6. WPO: This tag represents an objective relative pronoun (e.g., \"whom\").\n",
    "7. WPS-HL: This tag represents a subjective relative pronoun in headline form (e.g., \"who\").\n",
    "8. CS-HL: This tag represents a subordinating conjunction in headline form (e.g., \"because\").\n",
    "9. DT-NC: This tag represents a noun phrase determiner in non-contract form (e.g., \"which\").\n",
    "10. DT: This tag represents a determiner that introduces a noun phrase (e.g., \"the\").\n",
    "11. WPS: This tag represents a subjective relative pronoun (e.g., \"who\").\n",
    "12. CS: This tag represents a subordinating conjunction (e.g., \"because\").\n",
    "\n",
    "These tags help to identify the various grammatical roles and relationships of the word \"that\" in different contexts within sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705ce626",
   "metadata": {},
   "source": [
    "c. List tags in order of decreasing frequency. What do the 20 most frequent tags represent?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ea008f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 most frequent tags:\n",
      "NN : 152470\n",
      "IN : 120557\n",
      "AT : 97959\n",
      "JJ : 64028\n",
      ". : 60638\n",
      ", : 58156\n",
      "NNS : 55110\n",
      "CC : 37718\n",
      "RB : 36464\n",
      "NP : 34476\n",
      "VB : 33693\n",
      "VBN : 29186\n",
      "VBD : 26167\n",
      "CS : 22143\n",
      "PPS : 18253\n",
      "VBG : 17893\n",
      "PP$ : 16872\n",
      "TO : 14918\n",
      "PPSS : 13802\n",
      "CD : 13510\n"
     ]
    }
   ],
   "source": [
    "tag_freq = nltk.FreqDist(tag for _, tag in brown.tagged_words())\n",
    "top_20_tags = tag_freq.most_common(20)\n",
    "print(\"Top 20 most frequent tags:\")\n",
    "for tag, freq in top_20_tags:\n",
    "    print(tag, \":\", freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe51b2e",
   "metadata": {},
   "source": [
    "These tags are like labels that tell us what each word is doing in a sentence. For example, they can tell us if a word is a noun (like \"cat\" or \"dog\"), a verb (like \"run\" or \"eat\"), or a describing word (like \"big\" or \"happy\"). These labels are really important for computers to understand sentences properly. They help computers with tasks like figuring out the structure of a sentence, identifying different parts of speech, and understanding the meaning of words in a sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07520396",
   "metadata": {},
   "source": [
    "d. Which tags are nouns most commonly found after? What do these tags represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ec980cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 tags most commonly found after nouns:\n",
      "IN : 57873\n",
      ". : 28988\n",
      ", : 27676\n",
      "CC : 13811\n",
      "NN : 13774\n",
      "NNS : 6795\n",
      "VBD : 5210\n",
      "CS : 4521\n",
      "MD : 4291\n",
      "BEZ : 4281\n"
     ]
    }
   ],
   "source": [
    "noun_followed_by_tags = defaultdict(int)\n",
    "prev_tag = None\n",
    "\n",
    "for _, tag in brown.tagged_words():\n",
    "    if prev_tag and prev_tag.startswith('NN'):\n",
    "        noun_followed_by_tags[tag] += 1\n",
    "    prev_tag = tag\n",
    "\n",
    "# Here we are getting the top 10 most common tags found after nouns\n",
    "top_10_after_noun = sorted(noun_followed_by_tags.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "print(\"Top 10 tags most commonly found after nouns:\")\n",
    "for tag, count in top_10_after_noun:\n",
    "    print(tag, \":\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24065349",
   "metadata": {},
   "source": [
    "These are the top 10 tags most commonly found after nouns in the Brown Corpus:\n",
    "\n",
    "1. IN: Preposition or subordinating conjunction\n",
    "2. .: Sentence-final punctuation (period)\n",
    "3. ,: Comma\n",
    "4. CC: Coordinating conjunction\n",
    "5. NN: Singular noun\n",
    "6. NNS: Plural noun\n",
    "7. VBD: Past tense verb\n",
    "8. CS: Subordinating conjunction\n",
    "9. MD: Modal auxiliary\n",
    "10. BEZ: Third person singular present tense verb (inflectional form of \"be\")\n",
    "\n",
    "These tags represent various parts of speech and grammatical functions that frequently occur after nouns in English sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf400f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
