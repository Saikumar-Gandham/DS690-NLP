{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1aa1ff6",
   "metadata": {},
   "source": [
    "#### Name: Sai Kumar Gandham\n",
    "#### StudentID: IG45378"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a5bad3",
   "metadata": {},
   "source": [
    "#### The twenty user groups dataset is know to have several words in it that make classification tasks easy, use NLTK's distribution function to find words that appear in 97.5% of of all documents or in less than 2.5% of the documents. Using a count vectorizer add those words to the stop_words parameter. What does this do to the accuracy of the classifier on the training set? On the testing set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "549bc767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/saikumargandham/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/saikumargandham/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Downloading NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Fetching 20 Newsgroups dataset\n",
    "twenty_users = datasets.fetch_20newsgroups()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eece7be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saikumargandham/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the corpus\n",
    "X = vectorizer.fit_transform(twenty_users.data)\n",
    "\n",
    "# Get the document frequency of each word\n",
    "word_document_freq = np.sum(X > 0, axis=0).A1\n",
    "\n",
    "# Calculate the threshold for document frequency\n",
    "threshold_high = np.percentile(word_document_freq, 97.5)\n",
    "threshold_low = np.percentile(word_document_freq, 2.5)\n",
    "\n",
    "# Here We are getting words with document frequency greater than threshold_high or less than threshold_low\n",
    "selected_words = [word for word, freq in zip(vectorizer.get_feature_names(), word_document_freq)\n",
    "                  if freq > threshold_high or freq < threshold_low]\n",
    "\n",
    "# Initializing stop words with the current stop words or an empty set if None\n",
    "stop_words = vectorizer.get_stop_words() or set()\n",
    "\n",
    "# Adding the selected words to stop words\n",
    "stop_words.update(selected_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfcc9e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting stop words parameter of CountVectorizer\n",
    "vectorizer.set_params(stop_words=stop_words)\n",
    "\n",
    "# Fit and transform the corpus again with updated stop words\n",
    "X_updated = vectorizer.fit_transform(twenty_users.data)\n",
    "\n",
    "# Create a Multinomial Naive Bayes classifier\n",
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5007b937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9804441498176997\n",
      "Testing Accuracy: 0.866548828988069\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_updated, twenty_users.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# First Let's Predict on the training set\n",
    "train_predictions = clf.predict(X_train)\n",
    "\n",
    "# Calculating training accuracy\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "\n",
    "# Predict on the testing set\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "# Calculate testing accuracy\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "# Print accuracies\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a8751c",
   "metadata": {},
   "source": [
    "High Training Accuracy: The model learned the training data really well (98% accuracy).\n",
    "\n",
    "Slightly Lower Testing Accuracy: When tested on new data, the accuracy dropped a bit (87%). It's still good, but not as high as the training accuracy.\n",
    "\n",
    "Potential Overfitting: The big difference between how well the model did on the training and testing data could mean it's too focused on the training data. This might make it struggle when dealing with new, unseen information. We might need to look more closely at the model and make some changes to help it perform better with new data.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8bf4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
